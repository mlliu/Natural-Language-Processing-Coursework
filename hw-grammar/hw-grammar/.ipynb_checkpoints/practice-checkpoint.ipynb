{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c70769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc61628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\n"
     ]
    }
   ],
   "source": [
    "sampleList = [100, 200]\n",
    "randomList = random.choices(\n",
    "  sampleList, cum_weights=(1,100), k=1)\n",
    "  \n",
    "print(randomList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49622c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROOT': [[['S', '.'], ['S', '!'], ['is', 'it', 'true', 'that', 'S', '?']], [1, 1, 1]], 'S': [[['NP', 'VP']], [1]], 'VP': [[['Verb', 'NP']], [1]], 'NP': [[['Det', 'Noun'], ['NP', 'PP']], [1, 1]], 'PP': [[['Prep', 'NP']], [1]], 'Noun': [[['Adj', 'Noun'], ['president'], ['sandwich'], ['pickle'], ['chief', 'of', 'staff'], ['floor']], [1, 1, 1, 1, 1, 1]], 'Verb': [[['ate'], ['wanted'], ['kissed'], ['understood'], ['pickled']], [1, 1, 1, 1, 1]], 'Det': [[['the'], ['a'], ['every']], [1, 1, 1]], 'Adj': [[['fine'], ['delicious'], ['perplexed'], ['pickled']], [1, 1, 1, 1]], 'Prep': [[['with'], ['on'], ['under'], ['in']], [1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load rule from file\n",
    "first we need to read each line of the grammar.gr, skip empty lines and lines start with #\n",
    "split each line with \t, get count, key, value, then split the value by space, get the value list, such as NP VP\n",
    "if the key is not in rules, rules[key]=[[value_list],[count]]\n",
    "else:\n",
    "    rules[key][0].append(value_list)\n",
    "    rules[key][1].append(count)\n",
    "\n",
    "\n",
    "we need a dictionary/hashmap: rules={key:[options,weight for each option]}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_rules_from_file(grammar_file):\n",
    "    rules = {}\n",
    "    with open(grammar_file) as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            if not line.strip() or line.startswith(\"#\"):\n",
    "                continue\n",
    "            else:\n",
    "                #print(line)\n",
    "                line.splitlines() \n",
    "                count,key,values = line.split(\"\\t\")\n",
    "                value_list = values.split(\" \") \n",
    "                #for case 1\tROOT\tis it true that S ?     # mixing terminals and nonterminals is ok\n",
    "                #print(key,value_list)\n",
    "                for i in range(len(value_list)):\n",
    "                    if value_list[i]=='':\n",
    "                        value_list = value_list[:i]\n",
    "                        break\n",
    "                \n",
    "                if key not in rules:\n",
    "                    rules[key]=[[value_list],[int(count)]]\n",
    "                else:\n",
    "                    rules[key][0].append(value_list)\n",
    "                    rules[key][1].append(int(count))\n",
    "    return rules\n",
    "    \n",
    "    \n",
    "    \n",
    "grammar_file = \"grammar.gr\"\n",
    "rules = load_rules_from_file(grammar_file)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8f0d5c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'expansion' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a4c4da2d8c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mstart_symbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ROOT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-a4c4da2d8c52>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(symbol)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m#if exceed the maximal number of nonterminals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_expansions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'expansion' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sample use a recursion/dfs\n",
    "output=\"\"\n",
    "def dfs(node):\n",
    "    #base case the node is leaf node/terminal symbols\n",
    "    append the node to the output list\n",
    "    \n",
    "    #otherwise, sample one possible structure\n",
    "    childrens = random.choices(rules[node][0], cum_weights=rules[node][1], k=1)\n",
    "    for child in childrens:\n",
    "        dfs(child)\n",
    "    \n",
    "\n",
    "dfs(node = \"root\")\n",
    "\n",
    "\"\"\"\n",
    "output=[]\n",
    "max_expansions = 10\n",
    "expansion = 0 # global variables\n",
    "def dfs(symbol):\n",
    "    print(expansion)\n",
    "    #if exceed the maximal number of nonterminals\n",
    "    if expansion > max_expansions:\n",
    "        output.append(\"...\")\n",
    "        return\n",
    "    \n",
    "    #base case\n",
    "    if symbol not in rules:\n",
    "        output.append(symbol)\n",
    "        return \n",
    "    #otherwise\n",
    "    \n",
    "    childrens = random.choices(rules[symbol][0], weights=rules[symbol][1], k=1)[0]\n",
    "    for child in childrens:\n",
    "        expansion = expansion+ 1\n",
    "        dfs(child)\n",
    "start_symbol = 'ROOT'\n",
    "dfs(start_symbol)       \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa944c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Symbols in the grammar are case-sensitive.', '# ', '# This grammar uses a convention that', '#    - terminals are usually lowercase  (president)', '#    - preterminals are capitalized     (Noun)', '#    - other nonterminals are all-caps  (NP)', '# ', '# This convention just makes grammars more readable to humans.  Thus:', '#', '#    - When *you* are writing grammars in questions 3 and 6, you should ', '#      follow this convention unless you have a good reason not to.  ', '#', \"#    - But your *program* should still work with grammars that don't\", '#      follow this convention.  So how can your program reliably tell', '#      the difference between terminal and nonterminal symbols?  If', '#      there is at least one rule for rewriting a symbol, then that', '#      symbol is a nonterminal and should be rewritten.', '#######################', '', '# Rules for creating full sentences.', '', '1\\tROOT\\tS .', '1\\tROOT\\tS !', '1\\tROOT\\tis it true that S ?     # mixing terminals and nonterminals is ok.', '', \"# The basic grammar rules.  Here's what the abbreviations stand for:\", '#    S  = sentence', '#    NP = noun phrase', '#    VP = verb phrase', '#    PP = prepositional phrase', '#    Det = determiner (sometimes called \"article\")', '#    Prep = preposition', '#    Adj = adjective', '', '1\\tS\\tNP VP', '1\\tVP\\tVerb NP', '1\\tNP\\tDet Noun', '1\\tNP\\tNP PP', '1\\tPP\\tPrep NP', '1\\tNoun\\tAdj Noun', '', '# Vocabulary.  Your program can see that \"ate\" is a terminal', '# symbol because there exists no rule for rewriting it.', '# Any symbol that can rewrite as a terminal (or a string of ', '# terminals, like \"chief of staff\") is called a \"preterminal.\"  Notice ', '# that a preterminal is a special kind of nonterminal.', '', '1\\tVerb\\tate', '1\\tVerb\\twanted', '1\\tVerb\\tkissed', '1\\tVerb\\tunderstood', '1\\tVerb\\tpickled', '', '1\\tDet\\tthe', '1\\tDet\\ta', '1\\tDet\\tevery', '', '1\\tNoun\\tpresident', '1\\tNoun\\tsandwich', '1\\tNoun\\tpickle', '1\\tNoun\\tchief of staff', '1\\tNoun\\tfloor', '', '1\\tAdj\\tfine', '1\\tAdj\\tdelicious', '1\\tAdj\\tperplexed', '1\\tAdj\\tpickled', '', '1\\tPrep\\twith', '1\\tPrep\\ton', '1\\tPrep\\tunder', '1\\tPrep\\tin']\n"
     ]
    }
   ],
   "source": [
    "with open(grammar_file) as f:\n",
    "    lines = f.read().splitlines() \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a059bb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'it',\n",
       " 'true',\n",
       " 'that',\n",
       " 'S',\n",
       " '?',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '#',\n",
       " 'mixing',\n",
       " 'terminals',\n",
       " 'and',\n",
       " 'nonterminals',\n",
       " 'is',\n",
       " 'ok']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = \"is it true that S ?     # mixing terminals and nonterminals is ok\"\n",
    "value.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1520617",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #helper function,combine nonterminal \n",
    "    #['is', 'it', 'true', 'that', 'S', '?'] --> ['is it true that', 'S', '?'], count stay unchanged\n",
    "    def combNonterm(self,value_list):\n",
    "        \n",
    "        comb_value_list = [value_list[0]]\n",
    "        flag = True if values_list[0] not in self.values else False\n",
    "        for i in range(1,len(values_list)):\n",
    "            if values_list[i] not in self.rules:\n",
    "                #\n",
    "                if not flag:\n",
    "                    flag=True\n",
    "                    comb_value_list.appned(values_list[i])\n",
    "                else:\n",
    "                    #comb\n",
    "                    comb_value_list[-1] = comb_value_list[-1]+' '+ values_list[i]\n",
    "            else\n",
    "                flag=False\n",
    "                comb_value_list.appned(values_list[i])\n",
    "            \n",
    "        return comb_value_list\n",
    "                \n",
    "    def combNonterminal(self):\n",
    "        \"\"\"\n",
    "        iterate through each item of self.rules, \n",
    "        \n",
    "        \"\"\"\n",
    "        for key,vc in self.rules:\n",
    "            values,count =vc[0],vc[1]\n",
    "            #self.rules[key][0][1] = []\n",
    "            for i in range(len(values)):\n",
    "                values_list = values[i]\n",
    "                new_values_list = [values_list[0]]\n",
    "                #check if there is any non-terminals in the values list\n",
    "                flag = True if values_list[0] not in self.values else False\n",
    "                for j in range(1,values_list):\n",
    "                    if values_list[j] not in self.values and flag:\n",
    "                        #comb the current one with the last one\n",
    "                        new_values_list[-1] = new_values_list[-1]+\" \"+values_list[j]\n",
    "                    else:\n",
    "                        flag=False\n",
    "                        new_values_list.appned(values_list[j])\n",
    "                self.rules[key][0][1][i] = new_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c1a00328",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-127-762b6bf43694>, line 79)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-127-762b6bf43694>\"\u001b[0;36m, line \u001b[0;32m79\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Grammar:\n",
    "    def __init__(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Context-Free Grammar (CFG) Sentence Generator\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to a .gr grammar file\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Parse the input grammar file\n",
    "        self.rules = None\n",
    "        self._load_rules_from_file(grammar_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    def _load_rules_from_file(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Read grammar file and store its rules in self.rules\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to the raw grammar file \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        1.first we need to read each line of the grammar.gr, skip empty lines and lines start with #\n",
    "        2,split each line with \t, get count, key, value, then split the value by space, get the value list, such as NP VP\n",
    "        3.if the key is not in rules, rules[key]=[[value_list],[count]]\n",
    "        else:\n",
    "            rules[key][0].append(value_list)\n",
    "            rules[key][1].append(count)\n",
    "\n",
    "\n",
    "        we need a dictionary/hashmap: rules={key:[options,weight for each option]}\n",
    "\n",
    "        \"\"\"\n",
    "        self.rules = {}\n",
    "        with open(grammar_file) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            for line in lines:\n",
    "                if not line.strip() or line.startswith(\"#\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    #print(line)\n",
    "                    line.splitlines() \n",
    "                    count,key,values = line.split(\"\\t\")\n",
    "                    value_list = values.split(\" \") \n",
    "                    #for case 1\tROOT\tis it true that S ?     # mixing terminals and nonterminals is ok\n",
    "                    for i in range(len(value_list)):\n",
    "                        if value_list[i]==''or value_list[i]=='#':\n",
    "                            value_list = value_list[:i]\n",
    "                            break\n",
    "                            \n",
    "                    \n",
    "                    if key not in self.rules:\n",
    "                        self.rules[key]=[[value_list],[int(count)]]\n",
    "                    else:\n",
    "                        self.rules[key][0].append(value_list)\n",
    "                        self.rules[key][1].append(int(count))\n",
    "        #return self.rules\n",
    "        #raise NotImplementedError\n",
    "    \n",
    "\n",
    "                        \n",
    "    def sample(self, derivation_tree, max_expansions, start_symbol):\n",
    "        \"\"\"\n",
    "        Sample a random sentence from this grammar\n",
    "\n",
    "        Args:\n",
    "            derivation_tree (bool): if true, the returned string will represent \n",
    "                the tree (using bracket notation) that records how the sentence \n",
    "                was derived\n",
    "                               \n",
    "            max_expansions (int): max number of nonterminal expansions we allow\n",
    "\n",
    "            start_symbol (str): start symbol to generate from\n",
    "\n",
    "        Returns:\n",
    "            str: the random sentence or its derivation tree\n",
    "        \"\"\"\n",
    "        self.output=[]\n",
    "        self.expansion = 0 # global variables\n",
    "        self.max_expansions = max_expansions\n",
    "        self.dfs(start_symbol)\n",
    "        #return self.output\n",
    "        return \" \".join(self.output)\n",
    "    \n",
    "    def dfs(self,symbol):\n",
    "        print(self.expansion,symbol)\n",
    "        #if exceed the maximal number of nonterminals\n",
    "        if self.expansion > self.max_expansions:\n",
    "            self.output.append(\"...\")\n",
    "            return\n",
    "\n",
    "        #base case\n",
    "        if symbol not in rules:\n",
    "            self.output.append(symbol)\n",
    "            #self.output.append(\")\")\n",
    "            return \n",
    "        #otherwise\n",
    "        #self.output.append(\"(\")\n",
    "        #self.output.append(symbol)\n",
    "        children = random.choices(self.rules[symbol][0], weights=self.rules[symbol][1], k=1)[0]\n",
    "        self.expansion+= 1\n",
    "        for child in children:\n",
    "            #self.expansion+= 1\n",
    "            self.dfs(child)\n",
    "\n",
    "        #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "993f8133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROOT': [[['S', '.'], ['S', '!'], ['is', 'it', 'true', 'that', 'S', '?']], [1, 1, 1]], 'S': [[['NP', 'VP']], [1]], 'VP': [[['Verb', 'NP']], [1]], 'NP': [[['Det', 'Noun'], ['NP', 'PP']], [1, 1]], 'PP': [[['Prep', 'NP']], [1]], 'Noun': [[['Adj', 'Noun'], ['president'], ['sandwich'], ['pickle'], ['chief', 'of', 'staff'], ['floor']], [1, 1, 1, 1, 1, 1]], 'Verb': [[['ate'], ['wanted'], ['kissed'], ['understood'], ['pickled']], [1, 1, 1, 1, 1]], 'Det': [[['the'], ['a'], ['every']], [1, 1, 1]], 'Adj': [[['fine'], ['delicious'], ['perplexed'], ['pickled']], [1, 1, 1, 1]], 'Prep': [[['with'], ['on'], ['under'], ['in']], [1, 1, 1, 1]]}\n",
      "0 ROOT\n",
      "1 is\n",
      "2 it\n",
      "3 true\n",
      "4 that\n",
      "5 S\n",
      "6 NP\n",
      "7 Det\n",
      "8 the\n",
      "9 Noun\n",
      "10 Adj\n",
      "11 fine\n",
      "12 Noun\n",
      "13 VP\n",
      "14 ?\n",
      "is it true that the ... ... ... ...\n"
     ]
    }
   ],
   "source": [
    "grammar_file = \"grammar.gr\"\n",
    "grammar = Grammar(grammar_file)\n",
    "#grammer._load_rules_from_file(grammar_file)\n",
    "print(grammar.rules)\n",
    "print(grammar.sample(derivation_tree=False, max_expansions=10, start_symbol=\"ROOT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c112542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 2'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=[\"1\",\"2\"]\n",
    "\" \".join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b42c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70c08955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c18dc95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"aba\"\n",
    "s==s[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b4b15ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2]+[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72574dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
