{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c70769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc61628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\n"
     ]
    }
   ],
   "source": [
    "sampleList = [100, 200]\n",
    "randomList = random.choices(\n",
    "  sampleList, cum_weights=(1,100), k=1)\n",
    "  \n",
    "print(randomList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49622c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROOT': [[['S', '.'], ['S', '!'], ['is', 'it', 'true', 'that', 'S', '?']], [1, 1, 1]], 'S': [[['NP', 'VP']], [1]], 'VP': [[['Verb', 'NP']], [1]], 'NP': [[['Det', 'Noun'], ['NP', 'PP']], [1, 1]], 'PP': [[['Prep', 'NP']], [1]], 'Noun': [[['Adj', 'Noun'], ['president'], ['sandwich'], ['pickle'], ['chief', 'of', 'staff'], ['floor']], [1, 1, 1, 1, 1, 1]], 'Verb': [[['ate'], ['wanted'], ['kissed'], ['understood'], ['pickled']], [1, 1, 1, 1, 1]], 'Det': [[['the'], ['a'], ['every']], [1, 1, 1]], 'Adj': [[['fine'], ['delicious'], ['perplexed'], ['pickled']], [1, 1, 1, 1]], 'Prep': [[['with'], ['on'], ['under'], ['in']], [1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "load rule from file\n",
    "first we need to read each line of the grammar.gr, skip empty lines and lines start with #\n",
    "split each line with \t, get count, key, value, then split the value by space, get the value list, such as NP VP\n",
    "if the key is not in rules, rules[key]=[[value_list],[count]]\n",
    "else:\n",
    "    rules[key][0].append(value_list)\n",
    "    rules[key][1].append(count)\n",
    "\n",
    "\n",
    "we need a dictionary/hashmap: rules={key:[options,weight for each option]}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_rules_from_file(grammar_file):\n",
    "    rules = {}\n",
    "    with open(grammar_file) as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            if not line.strip() or line.startswith(\"#\"):\n",
    "                continue\n",
    "            else:\n",
    "                #print(line)\n",
    "                line.splitlines() \n",
    "                count,key,values = line.split(\"\\t\")\n",
    "                value_list = values.split(\" \") \n",
    "                #for case 1\tROOT\tis it true that S ?     # mixing terminals and nonterminals is ok\n",
    "                #print(key,value_list)\n",
    "                for i in range(len(value_list)):\n",
    "                    if value_list[i]=='':\n",
    "                        value_list = value_list[:i]\n",
    "                        break\n",
    "                \n",
    "                if key not in rules:\n",
    "                    rules[key]=[[value_list],[int(count)]]\n",
    "                else:\n",
    "                    rules[key][0].append(value_list)\n",
    "                    rules[key][1].append(int(count))\n",
    "    return rules\n",
    "    \n",
    "    \n",
    "    \n",
    "grammar_file = \"grammar.gr\"\n",
    "rules = load_rules_from_file(grammar_file)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8f0d5c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'expansion' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a4c4da2d8c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mstart_symbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ROOT'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-a4c4da2d8c52>\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(symbol)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpansion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m#if exceed the maximal number of nonterminals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexpansion\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_expansions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'expansion' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sample use a recursion/dfs\n",
    "output=\"\"\n",
    "def dfs(node):\n",
    "    #base case the node is leaf node/terminal symbols\n",
    "    append the node to the output list\n",
    "    \n",
    "    #otherwise, sample one possible structure\n",
    "    childrens = random.choices(rules[node][0], cum_weights=rules[node][1], k=1)\n",
    "    for child in childrens:\n",
    "        dfs(child)\n",
    "    \n",
    "\n",
    "dfs(node = \"root\")\n",
    "\n",
    "\"\"\"\n",
    "output=[]\n",
    "max_expansions = 10\n",
    "expansion = 0 # global variables\n",
    "def dfs(symbol):\n",
    "    print(expansion)\n",
    "    #if exceed the maximal number of nonterminals\n",
    "    if expansion > max_expansions:\n",
    "        output.append(\"...\")\n",
    "        return\n",
    "    \n",
    "    #base case\n",
    "    if symbol not in rules:\n",
    "        output.append(symbol)\n",
    "        return \n",
    "    #otherwise\n",
    "    \n",
    "    childrens = random.choices(rules[symbol][0], weights=rules[symbol][1], k=1)[0]\n",
    "    for child in childrens:\n",
    "        expansion = expansion+ 1\n",
    "        dfs(child)\n",
    "start_symbol = 'ROOT'\n",
    "dfs(start_symbol)       \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aa944c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Symbols in the grammar are case-sensitive.', '# ', '# This grammar uses a convention that', '#    - terminals are usually lowercase  (president)', '#    - preterminals are capitalized     (Noun)', '#    - other nonterminals are all-caps  (NP)', '# ', '# This convention just makes grammars more readable to humans.  Thus:', '#', '#    - When *you* are writing grammars in questions 3 and 6, you should ', '#      follow this convention unless you have a good reason not to.  ', '#', \"#    - But your *program* should still work with grammars that don't\", '#      follow this convention.  So how can your program reliably tell', '#      the difference between terminal and nonterminal symbols?  If', '#      there is at least one rule for rewriting a symbol, then that', '#      symbol is a nonterminal and should be rewritten.', '#######################', '', '# Rules for creating full sentences.', '', '1\\tROOT\\tS .', '1\\tROOT\\tS !', '1\\tROOT\\tis it true that S ?     # mixing terminals and nonterminals is ok.', '', \"# The basic grammar rules.  Here's what the abbreviations stand for:\", '#    S  = sentence', '#    NP = noun phrase', '#    VP = verb phrase', '#    PP = prepositional phrase', '#    Det = determiner (sometimes called \"article\")', '#    Prep = preposition', '#    Adj = adjective', '', '1\\tS\\tNP VP', '1\\tVP\\tVerb NP', '1\\tNP\\tDet Noun', '1\\tNP\\tNP PP', '1\\tPP\\tPrep NP', '1\\tNoun\\tAdj Noun', '', '# Vocabulary.  Your program can see that \"ate\" is a terminal', '# symbol because there exists no rule for rewriting it.', '# Any symbol that can rewrite as a terminal (or a string of ', '# terminals, like \"chief of staff\") is called a \"preterminal.\"  Notice ', '# that a preterminal is a special kind of nonterminal.', '', '1\\tVerb\\tate', '1\\tVerb\\twanted', '1\\tVerb\\tkissed', '1\\tVerb\\tunderstood', '1\\tVerb\\tpickled', '', '1\\tDet\\tthe', '1\\tDet\\ta', '1\\tDet\\tevery', '', '1\\tNoun\\tpresident', '1\\tNoun\\tsandwich', '1\\tNoun\\tpickle', '1\\tNoun\\tchief of staff', '1\\tNoun\\tfloor', '', '1\\tAdj\\tfine', '1\\tAdj\\tdelicious', '1\\tAdj\\tperplexed', '1\\tAdj\\tpickled', '', '1\\tPrep\\twith', '1\\tPrep\\ton', '1\\tPrep\\tunder', '1\\tPrep\\tin']\n"
     ]
    }
   ],
   "source": [
    "with open(grammar_file) as f:\n",
    "    lines = f.read().splitlines() \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac5ee1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'it',\n",
       " 'true',\n",
       " 'that',\n",
       " 'S',\n",
       " '?',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '#',\n",
       " 'mixing',\n",
       " 'terminals',\n",
       " 'and',\n",
       " 'nonterminals',\n",
       " 'is',\n",
       " 'ok']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = \"is it true that S ?     # mixing terminals and nonterminals is ok\"\n",
    "value.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #helper function,combine nonterminal \n",
    "    #['is', 'it', 'true', 'that', 'S', '?'] --> ['is it true that', 'S', '?'], count stay unchanged\n",
    "    def comb(self,value_list):\n",
    "        \n",
    "        comb_value_list = [value_list[0]]\n",
    "        flag = True if values_list[0] not in self.values else False\n",
    "        for i in range(1,len(values_list)):\n",
    "            if values_list[i] not in self.rules:\n",
    "                #\n",
    "                if not flag:\n",
    "                    flag=True\n",
    "                    comb_value_list.appned(values_list[i])\n",
    "                else:\n",
    "                    #comb\n",
    "                    comb_value_list[-1] = comb_value_list[-1]+' '+ values_list[i]\n",
    "            else\n",
    "                flag=False\n",
    "                comb_value_list.appned(values_list[i])\n",
    "            \n",
    "        return comb_value_list\n",
    "                \n",
    "    def combNonterminals(self):\n",
    "        \"\"\"\n",
    "        iterate through each item of self.rules, \n",
    "        \n",
    "        \"\"\"\n",
    "        for key,vc in self.rules:\n",
    "            values,count =vc[0],vc[1]\n",
    "            #self.rules[key][0][i] = []\n",
    "            for i in range(len(values)):\n",
    "                value_list = values[i]\n",
    "                comb_value_list = self.comb(value_list)\n",
    "                self.rules[key][0][i] = comb_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c1a00328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar:\n",
    "    def __init__(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Context-Free Grammar (CFG) Sentence Generator\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to a .gr grammar file\n",
    "        \n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Parse the input grammar file\n",
    "        self.rules = None\n",
    "        self._load_rules_from_file(grammar_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    def _load_rules_from_file(self, grammar_file):\n",
    "        \"\"\"\n",
    "        Read grammar file and store its rules in self.rules\n",
    "\n",
    "        Args:\n",
    "            grammar_file (str): Path to the raw grammar file \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        1.first we need to read each line of the grammar.gr, skip empty lines and lines start with #\n",
    "        2,split each line with \t, get count, key, value, then split the value by space, get the value list, such as NP VP\n",
    "        3.if the key is not in rules, rules[key]=[[value_list],[count]]\n",
    "        else:\n",
    "            rules[key][0].append(value_list)\n",
    "            rules[key][1].append(count)\n",
    "\n",
    "\n",
    "        we need a dictionary/hashmap: rules={key:[options,weight for each option]}\n",
    "\n",
    "        \"\"\"\n",
    "        self.rules = {}\n",
    "        with open(grammar_file) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            for line in lines:\n",
    "                if not line.strip() or line.startswith(\"#\"):\n",
    "                    continue\n",
    "                else:\n",
    "                    #print(line)\n",
    "                    line.splitlines() \n",
    "                    count,key,values = line.split(\"\\t\")\n",
    "                    value_list = values.split(\" \") \n",
    "                    #for case 1\tROOT\tis it true that S ?     # mixing terminals and nonterminals is ok\n",
    "                    for i in range(len(value_list)):\n",
    "                        if value_list[i]==''or value_list[i]=='#':\n",
    "                            value_list = value_list[:i]\n",
    "                            break\n",
    "                            \n",
    "                    \n",
    "                    if key not in self.rules:\n",
    "                        self.rules[key]=[[value_list],[int(count)]]\n",
    "                    else:\n",
    "                        self.rules[key][0].append(value_list)\n",
    "                        self.rules[key][1].append(int(count))\n",
    "        #comb Nonterminal items in self.rule\n",
    "        self.combNonterminals()\n",
    "        #return self.rules\n",
    "        #raise NotImplementedError\n",
    "        \n",
    "    #helper function,combine nonterminal for each list\n",
    "    #['is', 'it', 'true', 'that', 'S', '?'] --> ['is it true that', 'S', '?'], count stay unchanged\n",
    "    def comb(self,value_list):\n",
    "        \n",
    "        comb_value_list = [value_list[0]]\n",
    "        flag = True if value_list[0] not in self.rules else False\n",
    "        \n",
    "        for i in range(1,len(value_list)):\n",
    "            if value_list[i] not in self.rules:\n",
    "                #\n",
    "                if not flag:\n",
    "                    flag=True\n",
    "                    comb_value_list.append(value_list[i])\n",
    "                else:\n",
    "                    #comb\n",
    "                    comb_value_list[-1] = comb_value_list[-1]+' '+ value_list[i]\n",
    "            else:\n",
    "                flag=False\n",
    "                comb_value_list.append(value_list[i])\n",
    "            \n",
    "        return comb_value_list\n",
    "    \n",
    "    #comb nonterminals for the all hashtable\n",
    "    def combNonterminals(self):\n",
    "        \"\"\"\n",
    "        iterate through each item of self.rules, \n",
    "        \n",
    "        \"\"\"\n",
    "        for key in self.rules:\n",
    "            values=self.rules[key][0] #count remain unchanged\n",
    "            #self.rules[key][0][i] = []\n",
    "            for i in range(len(values)):\n",
    "                value_list = values[i]\n",
    "                comb_value_list = self.comb(value_list)\n",
    "                self.rules[key][0][i] = comb_value_list\n",
    "                \n",
    "    def sample(self, derivation_tree, max_expansions, start_symbol):\n",
    "        \"\"\"\n",
    "        Sample a random sentence from this grammar\n",
    "\n",
    "        Args:\n",
    "            derivation_tree (bool): if true, the returned string will represent \n",
    "                the tree (using bracket notation) that records how the sentence \n",
    "                was derived\n",
    "                               \n",
    "            max_expansions (int): max number of nonterminal expansions we allow\n",
    "\n",
    "            start_symbol (str): start symbol to generate from\n",
    "\n",
    "        Returns:\n",
    "            str: the random sentence or its derivation tree\n",
    "        \"\"\"\n",
    "        self.output=[]\n",
    "        self.expansion = 0 # global variables\n",
    "        self.max_expansions = max_expansions\n",
    "        if derivation_tree:\n",
    "            self.right=0 #number of right parenthese\n",
    "            self.dfs_tree(start_symbol)\n",
    "            self.output.append(\")\"*self.right)\n",
    "        else:\n",
    "            self.dfs(start_symbol)\n",
    "        #return self.output\n",
    "        return \" \".join(self.output)\n",
    "    \n",
    "    def dfs(self,symbol):\n",
    "        print(self.expansion,symbol)\n",
    "        #if exceed the maximal number of nonterminals\n",
    "        if self.expansion > self.max_expansions:\n",
    "            self.output.append(\"...\")\n",
    "            return\n",
    "\n",
    "        #base case\n",
    "        if symbol not in rules:\n",
    "            self.output.append(symbol)\n",
    "            return \n",
    "        #otherwise\n",
    "        children = random.choices(self.rules[symbol][0], weights=self.rules[symbol][1], k=1)[0]\n",
    "        self.expansion+= 1\n",
    "        for child in children:\n",
    "            #self.expansion+= 1\n",
    "            self.dfs(child)\n",
    "            \n",
    "    def dfs_tree(self,symbol):\n",
    "        print(self.expansion,symbol)\n",
    "        #if exceed the maximal number of nonterminals\n",
    "        if self.expansion > self.max_expansions:\n",
    "            self.output.append(\"...)\")\n",
    "            self.right-=1\n",
    "            return\n",
    "\n",
    "        #base case\n",
    "        if symbol not in rules:\n",
    "            self.output.append(symbol+\")\")\n",
    "            self.right-=1\n",
    "            return \n",
    "        #otherwise\n",
    "        self.output.append(\"(\" +symbol)\n",
    "        self.right+=1\n",
    "        children = random.choices(self.rules[symbol][0], weights=self.rules[symbol][1], k=1)[0]\n",
    "        self.expansion+= 1\n",
    "        for child in children:\n",
    "            #self.expansion+= 1\n",
    "            self.dfs_tree(child)\n",
    "\n",
    "        #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "993f8133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROOT': [[['S', '.'], ['S', '!'], ['is it true that', 'S', '?']], [1, 1, 1]], 'S': [[['NP', 'VP']], [1]], 'VP': [[['Verb', 'NP']], [1]], 'NP': [[['Det', 'Noun'], ['NP', 'PP']], [1, 1]], 'PP': [[['Prep', 'NP']], [1]], 'Noun': [[['Adj', 'Noun'], ['president'], ['sandwich'], ['pickle'], ['chief of staff'], ['floor']], [1, 1, 1, 1, 1, 1]], 'Verb': [[['ate'], ['wanted'], ['kissed'], ['understood'], ['pickled']], [1, 1, 1, 1, 1]], 'Det': [[['the'], ['a'], ['every']], [1, 1, 1]], 'Adj': [[['fine'], ['delicious'], ['perplexed'], ['pickled']], [1, 1, 1, 1]], 'Prep': [[['with'], ['on'], ['under'], ['in']], [1, 1, 1, 1]]}\n",
      "0 ROOT\n",
      "1 is it true that\n",
      "1 S\n",
      "2 NP\n",
      "3 Det\n",
      "4 a\n",
      "4 Noun\n",
      "5 sandwich\n",
      "5 VP\n",
      "6 Verb\n",
      "7 wanted\n",
      "7 NP\n",
      "8 NP\n",
      "9 Det\n",
      "10 the\n",
      "10 Noun\n",
      "11 pickle\n",
      "11 PP\n",
      "12 Prep\n",
      "13 with\n",
      "13 NP\n",
      "14 NP\n",
      "15 Det\n",
      "16 a\n",
      "16 Noun\n",
      "16 PP\n",
      "16 ?\n",
      "(ROOT is it true that) (S (NP (Det a) (Noun sandwich) (VP (Verb wanted) (NP (NP (Det the) (Noun pickle) (PP (Prep with) (NP (NP (Det ...) ...) ...) ...) )))))\n"
     ]
    }
   ],
   "source": [
    "grammar_file = \"grammar.gr\"\n",
    "derivation_tree = True\n",
    "max_expansions =15\n",
    "start_symbol = \"ROOT\"\n",
    "grammar = Grammar(grammar_file)\n",
    "#grammer._load_rules_from_file(grammar_file)\n",
    "print(grammar.rules)\n",
    "sentence = grammar.sample(derivation_tree, max_expansions, start_symbol)\n",
    "print(sentence)\n",
    "if derivation_tree:\n",
    "    prettyprint_path = os.path.join(os.getcwd(), 'prettyprint')\n",
    "    t = os.system(f\"echo '{sentence}' | perl {prettyprint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c112542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/meililiu/Desktop/Course/601.665 NLP/homework/hw-grammar/prettyprint'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettyprint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b42c87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '1']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70c08955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c18dc95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"aba\"\n",
    "s==s[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b4b15ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2]+[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72574dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= tuple([\"1\",\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f4e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c0638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae7059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', '2', '3')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+tuple(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113b8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa54f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98d045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.add(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5861795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update([3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d06231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca8979f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 2, 2, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'aabbbccdddddee'\n",
    "from collections import Counter\n",
    "counter = Counter(s)\n",
    "sorted(counter.values(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90de4440",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68714350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e92198d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1e823184850a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "sum(counter[1:][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d324c47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a58ba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =\"abdcs\"\n",
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8c1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"a\"*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7540187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaa'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a090cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =set((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f034e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d321920",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8bc71255a22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32792935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
